{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def visualize_multihead_attention_with_aspect():\n",
    "    # Create a new directed graph\n",
    "    graph = graphviz.Digraph(comment='MultiheadAttentionWithAspect', graph_attr={'rankdir': 'TB', 'size': '12,12'})\n",
    "\n",
    "    # Input nodes\n",
    "    graph.node('sentence_embedding', 'Sentence Embedding\\n[0.2, 0.5, ..., 0.1]\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('aspect_embedding', 'Aspect Embedding\\n[0.1, 0.3, ..., 0.2]\\nShape: (aspect_length, d_model)', shape='box', style='filled', fillcolor='lightblue')\n",
    "\n",
    "    # Concatenation and linear transformation\n",
    "    graph.node('concatenation', 'Concatenation\\nCombines sentence and aspect embeddings\\nShape: (batch_size, seq_length, 2 * d_model)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('query_linear', 'Query Linear\\nTransforms concatenated embeddings\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.edge('sentence_embedding', 'concatenation', label='sentence_embedding')\n",
    "    graph.edge('aspect_embedding', 'concatenation', label='aspect_embedding')\n",
    "    graph.edge('concatenation', 'query_linear', label='concatenated_query')\n",
    "\n",
    "    # Layer normalization and positional encoding\n",
    "    graph.node('layer_norm', 'Layer Normalization\\nNormalizes the query tensor\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('pos_encoding', 'Positional Encoding\\nAdds positional information to the query\\nShape: (seq_length, d_model)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.edge('query_linear', 'layer_norm', label='query')\n",
    "    graph.edge('layer_norm', 'pos_encoding', label='normalized_query')\n",
    "\n",
    "    # Linear transformations for Q, K, and V\n",
    "    graph.node('wq', 'Linear (Q)\\nCreates query vectors\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('wk', 'Linear (K)\\nCreates key vectors\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('wv', 'Linear (V)\\nCreates value vectors\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.edge('pos_encoding', 'wq', label='query')\n",
    "    graph.edge('pos_encoding', 'wk', label='query')\n",
    "    graph.edge('pos_encoding', 'wv', label='query')\n",
    "\n",
    "    # Reshaping and permutation for multi-head attention\n",
    "    graph.node('reshape_q', 'Reshape (Q)\\nReshapes query for multi-head attention\\nShape: (batch_size, num_heads, seq_length, depth)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('reshape_k', 'Reshape (K)\\nReshapes key for multi-head attention\\nShape: (batch_size, num_heads, seq_length, depth)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('reshape_v', 'Reshape (V)\\nReshapes value for multi-head attention\\nShape: (batch_size, num_heads, seq_length, depth)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('wq', 'reshape_q', label='Q')\n",
    "    graph.edge('wk', 'reshape_k', label='K')\n",
    "    graph.edge('wv', 'reshape_v', label='V')\n",
    "\n",
    "    # Multi-head attention\n",
    "    graph.node('matmul_qk', 'Matrix Multiplication (Q, K)\\nComputes attention scores\\nShape: (batch_size, num_heads, seq_length, seq_length)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.node('scale', 'Scaling\\nScales attention scores\\nShape: (batch_size, num_heads, seq_length, seq_length)', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('softmax', 'Softmax\\nNormalizes attention scores\\nShape: (batch_size, num_heads, seq_length, seq_length)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('dropout', 'Dropout\\nRegularizes attention scores\\nShape: (batch_size, num_heads, seq_length, seq_length)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('matmul_av', 'Matrix Multiplication (Attention, V)\\nComputes attention-weighted values\\nShape: (batch_size, num_heads, seq_length, depth)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.edge('reshape_q', 'matmul_qk', label='Q')\n",
    "    graph.edge('reshape_k', 'matmul_qk', label='K')\n",
    "    graph.edge('matmul_qk', 'scale', label='attention_scores')\n",
    "    graph.edge('scale', 'softmax', label='scaled_attention_scores')\n",
    "    graph.edge('softmax', 'dropout', label='attention_probs')\n",
    "    graph.edge('dropout', 'matmul_av', label='attention')\n",
    "    graph.edge('reshape_v', 'matmul_av', label='V')\n",
    "\n",
    "    # Reshape and linear transformation\n",
    "    graph.node('reshape_output', 'Reshape Output\\nReshapes attention output\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('fc_out', 'Linear\\nTransforms reshaped output\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.edge('matmul_av', 'reshape_output', label='weighted_value')\n",
    "    graph.edge('reshape_output', 'fc_out', label='reshaped_output')\n",
    "\n",
    "    # Residual connection and layer normalization\n",
    "    graph.node('residual', 'Residual Connection\\nAdds query to the transformed output\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('layer_norm_output', 'Layer Normalization\\nNormalizes the output\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.edge('fc_out', 'residual', label='output')\n",
    "    graph.edge('pos_encoding', 'residual', label='query')\n",
    "    graph.edge('residual', 'layer_norm_output', label='residual_output')\n",
    "\n",
    "    # Output nodes\n",
    "    graph.node('output', 'Output\\nContextual Embeddings\\n[0.7, 0.2, ..., 0.5]\\nShape: (batch_size, seq_length, d_model)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('attention_weights', 'Attention Weights\\n[[0.1, 0.2, ..., 0.05], ...]\\nShape: (batch_size, num_heads, seq_length, seq_length)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('layer_norm_output', 'output', label='output')\n",
    "    graph.edge('dropout', 'attention_weights', label='attention')\n",
    "\n",
    "    # Render and save the diagram\n",
    "    graph.render('multihead_attention_with_aspect_detailed', view=True)\n",
    "\n",
    "# Call the function to generate the diagram\n",
    "visualize_multihead_attention_with_aspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def visualize_multihead_attention_with_aspect():\n",
    "    # Create a new directed graph\n",
    "    graph = graphviz.Digraph(comment='MultiheadAttentionWithAspect', graph_attr={'rankdir': 'TB', 'size': '12,12', 'bgcolor': '#f0f8ff'})\n",
    "\n",
    "    # Define color palette\n",
    "    colors = {\n",
    "        'input': '#b3e6ff',\n",
    "        'embedding': '#ffd1dc',\n",
    "        'transformation': '#ccffcc',\n",
    "        'attention': '#ffffb3',\n",
    "        'normalization': '#ffb3b3',\n",
    "        'output': '#b3e6ff'\n",
    "    }\n",
    "\n",
    "    # Input nodes\n",
    "    with graph.subgraph(name='cluster_input', node_attr={'shape': 'rectangle', 'style': 'filled'}) as input_subgraph:\n",
    "        input_subgraph.attr(label='Input', color='#b3e6ff', style='filled')\n",
    "        input_subgraph.node('sentence_embedding', 'Sentence Embedding\\n[0.2, 0.5, ..., 0.1]\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['input'])\n",
    "        input_subgraph.node('aspect_embedding', 'Aspect Embedding\\n[0.1, 0.3, ..., 0.2]\\n<i>Shape: (aspect_length, d_model)</i>', fillcolor=colors['input'])\n",
    "\n",
    "    # Embedding and transformation nodes\n",
    "    with graph.subgraph(name='cluster_embedding', node_attr={'shape': 'rectangle', 'style': 'filled'}) as embedding_subgraph:\n",
    "        embedding_subgraph.attr(label='Embedding and Transformation', color='#ffd1dc', style='filled')\n",
    "        embedding_subgraph.node('concatenation', 'Concatenation\\nCombines sentence and aspect embeddings\\n<i>Shape: (batch_size, seq_length, 2 * d_model)</i>', fillcolor=colors['embedding'])\n",
    "        embedding_subgraph.node('query_linear', 'Query Linear\\nTransforms concatenated embeddings\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['transformation'])\n",
    "        embedding_subgraph.node('layer_norm', 'Layer Normalization\\nNormalizes the query tensor\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['normalization'])\n",
    "        embedding_subgraph.node('pos_encoding', 'Positional Encoding\\nAdds positional information to the query\\n<i>Shape: (seq_length, d_model)</i>', fillcolor=colors['transformation'])\n",
    "\n",
    "    # Linear transformations for Q, K, and V\n",
    "    with graph.subgraph(name='cluster_qkv', node_attr={'shape': 'rectangle', 'style': 'filled'}) as qkv_subgraph:\n",
    "        qkv_subgraph.attr(label='Linear Transformations (Q, K, V)', color='#ccffcc', style='filled')\n",
    "        qkv_subgraph.node('wq', 'Linear (Q)\\nCreates query vectors\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['transformation'])\n",
    "        qkv_subgraph.node('wk', 'Linear (K)\\nCreates key vectors\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['transformation'])\n",
    "        qkv_subgraph.node('wv', 'Linear (V)\\nCreates value vectors\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['transformation'])\n",
    "\n",
    "    # Reshaping and multi-head attention nodes\n",
    "    with graph.subgraph(name='cluster_attention', node_attr={'shape': 'rectangle', 'style': 'filled'}) as attention_subgraph:\n",
    "        attention_subgraph.attr(label='Multi-Head Attention', color='#ffffb3', style='filled')\n",
    "        attention_subgraph.node('reshape_q', 'Reshape (Q)\\n<i>Shape: (batch_size, num_heads, seq_length, depth)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('reshape_k', 'Reshape (K)\\n<i>Shape: (batch_size, num_heads, seq_length, depth)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('reshape_v', 'Reshape (V)\\n<i>Shape: (batch_size, num_heads, seq_length, depth)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('matmul_qk', 'Matrix Multiplication (Q, K)\\nComputes attention scores\\n<i>Shape: (batch_size, num_heads, seq_length, seq_length)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('scale', 'Scaling\\nScales attention scores\\n<i>Shape: (batch_size, num_heads, seq_length, seq_length)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('softmax', 'Softmax\\nNormalizes attention scores\\n<i>Shape: (batch_size, num_heads, seq_length, seq_length)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('dropout', 'Dropout\\nRegularizes attention scores\\n<i>Shape: (batch_size, num_heads, seq_length, seq_length)</i>', fillcolor=colors['attention'])\n",
    "        attention_subgraph.node('matmul_av', 'Matrix Multiplication (Attention, V)\\nComputes attention-weighted values\\n<i>Shape: (batch_size, num_heads, seq_length, depth)</i>', fillcolor=colors['attention'])\n",
    "\n",
    "    # Output nodes\n",
    "    with graph.subgraph(name='cluster_output', node_attr={'shape': 'rectangle', 'style': 'filled'}) as output_subgraph:\n",
    "        output_subgraph.attr(label='Output', color='#b3e6ff', style='filled')\n",
    "        output_subgraph.node('reshape_output', 'Reshape Output\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['output'])\n",
    "        output_subgraph.node('fc_out', 'Linear\\nTransforms reshaped output\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['output'])\n",
    "        output_subgraph.node('residual', 'Residual Connection\\nAdds query to the transformed output\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['output'])\n",
    "        output_subgraph.node('layer_norm_output', 'Layer Normalization\\nNormalizes the output\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['normalization'])\n",
    "        output_subgraph.node('output', 'Output\\nContextual Embeddings\\n[0.7, 0.2, ..., 0.5]\\n<i>Shape: (batch_size, seq_length, d_model)</i>', fillcolor=colors['output'])\n",
    "        output_subgraph.node('attention_weights', 'Attention Weights\\n[[0.1, 0.2, ..., 0.05], ...]\\n<i>Shape: (batch_size, num_heads, seq_length, seq_length)</i>', fillcolor=colors['attention'])\n",
    "\n",
    "    # Edges\n",
    "    graph.edge('sentence_embedding', 'concatenation', label='sentence_embedding')\n",
    "    graph.edge('aspect_embedding', 'concatenation', label='aspect_embedding')\n",
    "    graph.edge('concatenation', 'query_linear', label='concatenated_query')\n",
    "    graph.edge('query_linear', 'layer_norm', label='query')\n",
    "    graph.edge('layer_norm', 'pos_encoding', label='normalized_query')\n",
    "    graph.edge('pos_encoding', 'wq', label='query')\n",
    "    graph.edge('pos_encoding', 'wk', label='query')\n",
    "    graph.edge('pos_encoding', 'wv', label='query')\n",
    "    graph.edge('wq', 'reshape_q', label='Q')\n",
    "    graph.edge('wk', 'reshape_k', label='K')\n",
    "    graph.edge('wv', 'reshape_v', label='V')\n",
    "    graph.edge('reshape_q', 'matmul_qk', label='Q')\n",
    "    graph.edge('reshape_k', 'matmul_qk', label='K')\n",
    "    graph.edge('matmul_qk', 'scale', label='attention_scores')\n",
    "    graph.edge('scale', 'softmax', label='scaled_attention_scores')\n",
    "    graph.edge('softmax', 'dropout', label='attention_probs')\n",
    "    graph.edge('dropout', 'matmul_av', label='attention')\n",
    "    graph.edge('reshape_v', 'matmul_av', label='V')\n",
    "    graph.edge('matmul_av', 'reshape_output', label='weighted_value')\n",
    "    graph.edge('reshape_output', 'fc_out', label='reshaped_output')\n",
    "    graph.edge('fc_out', 'residual', label='output')\n",
    "    graph.edge('pos_encoding', 'residual', label='query')\n",
    "    graph.edge('residual', 'layer_norm_output', label='residual_output')\n",
    "    graph.edge('layer_norm_output', 'output', label='output')\n",
    "    graph.edge('dropout', 'attention_weights', label='attention')\n",
    "\n",
    "    # Legend\n",
    "    with graph.subgraph(name='cluster_legend', node_attr={'shape': 'plaintext'}) as legend_subgraph:\n",
    "        legend_subgraph.attr(label='Legend', color='black', style='filled', fillcolor='white')\n",
    "        legend_subgraph.node('legend', '''<\n",
    "            <table border=\"0\" cellborder=\"1\" cellspacing=\"0\" cellpadding=\"4\">\n",
    "            <tr><td bgcolor=\"{input}\">Input/Output</td></tr>\n",
    "            <tr><td bgcolor=\"{embedding}\">Embedding</td></tr>\n",
    "            <tr><td bgcolor=\"{transformation}\">Transformation</td></tr>\n",
    "            <tr><td bgcolor=\"{attention}\">Attention</td></tr>\n",
    "            <tr><td bgcolor=\"{normalization}\">Normalization</td></tr>\n",
    "            </table>\n",
    "        >'''.format(**colors))\n",
    "\n",
    "    # Render and save the diagram\n",
    "    graph.render('multihead_attention_with_aspect_improved', view=True)\n",
    "\n",
    "# Call the function to generate the diagram\n",
    "visualize_multihead_attention_with_aspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def visualize_multihead_attention_with_aspect_simplified():\n",
    "    graph = graphviz.Digraph(comment='MultiheadAttentionWithAspect (Simplified)', graph_attr={'rankdir': 'TB', 'size': '8,8', 'bgcolor': '#f0f8ff'})\n",
    "\n",
    "    colors = {\n",
    "        'input': '#b3e6ff',\n",
    "        'transformation': '#ccffcc',\n",
    "        'attention': '#ffffb3',\n",
    "        'output': '#b3e6ff'\n",
    "    }\n",
    "\n",
    "    # Input nodes\n",
    "    graph.node('sentence_embedding', 'Sentence Embedding', shape='rectangle', style='filled', fillcolor=colors['input'])\n",
    "    graph.node('aspect_embedding', 'Aspect Embedding', shape='rectangle', style='filled', fillcolor=colors['input'])\n",
    "\n",
    "    # Transformation nodes\n",
    "    graph.node('concatenation', 'Concatenation', shape='rectangle', style='filled', fillcolor=colors['transformation'])\n",
    "    graph.node('query_linear', 'Query Linear', shape='rectangle', style='filled', fillcolor=colors['transformation'])\n",
    "    graph.node('add_position', 'Add Positional Encoding', shape='rectangle', style='filled', fillcolor=colors['transformation'])\n",
    "    graph.node('qkv_linear', 'Linear (Q, K, V)', shape='rectangle', style='filled', fillcolor=colors['transformation'])\n",
    "\n",
    "    # Attention nodes\n",
    "    graph.node('attention', 'Multi-Head Attention', shape='rectangle', style='filled', fillcolor=colors['attention'])\n",
    "\n",
    "    # Output nodes\n",
    "    graph.node('output', 'Output', shape='rectangle', style='filled', fillcolor=colors['output'])\n",
    "\n",
    "    # Edges\n",
    "    graph.edge('sentence_embedding', 'concatenation', label='sentence_embedding')\n",
    "    graph.edge('aspect_embedding', 'concatenation', label='aspect_embedding')\n",
    "    graph.edge('concatenation', 'query_linear', label='concatenated_query')\n",
    "    graph.edge('query_linear', 'add_position', label='query')\n",
    "    graph.edge('add_position', 'qkv_linear', label='query_with_position')\n",
    "    graph.edge('qkv_linear', 'attention', label='Q, K, V')\n",
    "    graph.edge('attention', 'output', label='attended_output')\n",
    "\n",
    "    graph.render('multihead_attention_with_aspect_simplified', view=True)\n",
    "\n",
    "visualize_multihead_attention_with_aspect_simplified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def visualize_overall_process():\n",
    "    # Create a new directed graph\n",
    "    graph = graphviz.Digraph(comment='Overall Process', graph_attr={'rankdir': 'TB'})\n",
    "\n",
    "    # Input nodes\n",
    "    graph.node('sentence', 'Raw Sentence\\n\"The food was delicious, but the service was slow.\"', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('aspect', 'Aspect\\n\"food\", \"service\"', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('polarity', 'Polarity\\n\"positive\", \"negative\"', shape='box', style='filled', fillcolor='lightblue')\n",
    "\n",
    "    # RoBERTa embeddings\n",
    "    graph.node('roberta', 'RoBERTa\\nGenerates embeddings', shape='rectangle', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('sentence', 'roberta')\n",
    "    graph.edge('aspect', 'roberta')\n",
    "\n",
    "    # Attention mechanism\n",
    "    graph.node('attention', 'Attention Mechanism\\nGenerates contextual embeddings', shape='rectangle', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('roberta', 'attention')\n",
    "\n",
    "    # Contextual embeddings\n",
    "    graph.node('contextual_embeddings', 'Contextual Embeddings\\n[0.2, 0.5, ...], [0.1, 0.3, ...]', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.edge('attention', 'contextual_embeddings')\n",
    "\n",
    "    # Splitting into windows\n",
    "    graph.node('window_splitting', 'Window Splitting\\nSplits embeddings into windows', shape='rectangle', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('contextual_embeddings', 'window_splitting')\n",
    "\n",
    "    # Window embeddings\n",
    "    graph.node('window_embeddings', 'Window Embeddings\\n[[0.2, 0.5, ...], [0.1, 0.3, ...]], [[0.8, 0.2, ...], [0.4, 0.6, ...]]', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.edge('window_splitting', 'window_embeddings')\n",
    "\n",
    "    # Contrastive learning\n",
    "    graph.node('contrastive_learning', 'Contrastive Learning\\nLearns sentiment representations', shape='rectangle', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('window_embeddings', 'contrastive_learning')\n",
    "    graph.edge('polarity', 'contrastive_learning')\n",
    "\n",
    "    # Output node\n",
    "    graph.node('output', 'Sentiment Predictions\\nPositive: [0.8, 0.2]\\nNegative: [0.3, 0.7]', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.edge('contrastive_learning', 'output')\n",
    "\n",
    "    # Render and save the diagram\n",
    "    graph.render('overall_process', view=True)\n",
    "\n",
    "# Call the function to generate the diagram\n",
    "visualize_overall_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def visualize_contrastive_model():\n",
    "    # Create a new directed graph\n",
    "    graph = graphviz.Digraph(comment='ContrastiveModel', graph_attr={'rankdir': 'TB', 'size': '12,12'})\n",
    "\n",
    "    # Input nodes\n",
    "    graph.node('input_ids', 'Input IDs\\nShape: (batch_size, seq_length)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('attention_mask', 'Attention Mask\\nShape: (batch_size, seq_length)', shape='box', style='filled', fillcolor='lightblue')\n",
    "\n",
    "    # BERT layer\n",
    "    graph.node('bert', 'BERT Model\\nbert-base-uncased\\nOutput Shape: (batch_size, hidden_size)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('input_ids', 'bert', label='input_ids')\n",
    "    graph.edge('attention_mask', 'bert', label='attention_mask')\n",
    "\n",
    "    # Dropout and linear layers\n",
    "    graph.node('dropout1', 'Dropout\\nDropout rate: 0.5', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('fc1', 'Linear\\nInput Shape: (batch_size, hidden_size)\\nOutput Shape: (batch_size, hidden_dim)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.node('relu1', 'ReLU', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('dropout2', 'Dropout\\nDropout rate: 0.5', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('fc2', 'Linear\\nInput Shape: (batch_size, hidden_dim)\\nOutput Shape: (batch_size, hidden_dim // 2)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.node('relu2', 'ReLU', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('dropout3', 'Dropout\\nDropout rate: 0.5', shape='box', style='filled', fillcolor='lightpink')\n",
    "\n",
    "    graph.edge('bert', 'dropout1', label='pooled_output')\n",
    "    graph.edge('dropout1', 'fc1', label='x')\n",
    "    graph.edge('fc1', 'relu1', label='x')\n",
    "    graph.edge('relu1', 'dropout2', label='x')\n",
    "    graph.edge('dropout2', 'fc2', label='x')\n",
    "    graph.edge('fc2', 'relu2', label='x')\n",
    "    graph.edge('relu2', 'dropout3', label='x')\n",
    "\n",
    "    # Aspect-specific linear layers\n",
    "    graph.node('aspects_fc', 'ModuleList\\nmax_aspects Linear layers\\nInput Shape: (batch_size, hidden_dim // 2)\\nOutput Shape: (batch_size, n_classes)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.edge('dropout3', 'aspects_fc', label='x')\n",
    "\n",
    "    # Output nodes\n",
    "    graph.node('output_negative', 'Negative\\nShape: (batch_size, 1)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('output_neutral', 'Neutral\\nShape: (batch_size, 1)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('output_positive', 'Positive\\nShape: (batch_size, 1)', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('output_other', 'Other\\nShape: (batch_size, 1)', shape='box', style='filled', fillcolor='lightblue')\n",
    "\n",
    "    graph.edge('aspects_fc', 'output_negative', label='aspect_probabilities[0]')\n",
    "    graph.edge('aspects_fc', 'output_neutral', label='aspect_probabilities[1]')\n",
    "    graph.edge('aspects_fc', 'output_positive', label='aspect_probabilities[2]')\n",
    "    graph.edge('aspects_fc', 'output_other', label='aspect_probabilities[3]')\n",
    "\n",
    "    # Render and save the diagram\n",
    "    graph.render('contrastive_model', view=True)\n",
    "\n",
    "def visualize_contrastive_dataset():\n",
    "    # Create a new directed graph\n",
    "    graph = graphviz.Digraph(comment='ContrastiveDataset', graph_attr={'rankdir': 'LR', 'size': '12,8'})\n",
    "\n",
    "    # Input nodes\n",
    "    graph.node('positive_pairs', 'Positive Pairs\\n(tensor1, tensor2)\\nSample:\\n([0.1, 0.2, ...], [0.3, 0.4, ...])\\n([0.5, 0.6, ...], [0.7, 0.8, ...])', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('negative_pairs', 'Negative Pairs\\n(tensor1, tensor2)\\nSample:\\n([0.2, 0.3, ...], [0.9, 0.1, ...])\\n([0.4, 0.5, ...], [0.6, 0.7, ...])', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('positive_sentiments', 'Positive Sentiments\\nSample:\\n[2, 2]\\n[1, 2]', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('negative_sentiments', 'Negative Sentiments\\nSample:\\n[0, 2]\\n[1, 0]', shape='box', style='filled', fillcolor='lightgreen')\n",
    "\n",
    "    # ContrastiveDataset node\n",
    "    graph.node('contrastive_dataset', 'ContrastiveDataset\\n__init__(positive_pairs, negative_pairs,\\npositive_sentiments, negative_sentiments)\\n__len__(), __getitem__(idx)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "\n",
    "    graph.edge('positive_pairs', 'contrastive_dataset', label='pairs')\n",
    "    graph.edge('negative_pairs', 'contrastive_dataset', label='pairs')\n",
    "    graph.edge('positive_sentiments', 'contrastive_dataset', label='sentiments')\n",
    "    graph.edge('negative_sentiments', 'contrastive_dataset', label='sentiments')\n",
    "\n",
    "    # Output nodes\n",
    "    graph.node('pairs', 'Pairs\\n(tensor1, tensor2)\\nSample:\\n([0.1, 0.2, ...], [0.3, 0.4, ...])\\n([0.2, 0.3, ...], [0.9, 0.1, ...])', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('labels', 'Labels\\nSample:\\n[1, 0]', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('sentiments', 'Sentiments\\nSample:\\n[2, 2]\\n[0, 2]', shape='box', style='filled', fillcolor='lightgreen')\n",
    "\n",
    "    graph.edge('contrastive_dataset', 'pairs', label='self.pairs')\n",
    "    graph.edge('contrastive_dataset', 'labels', label='self.labels')\n",
    "    graph.edge('contrastive_dataset', 'sentiments', label='self.sentiments')\n",
    "\n",
    "    # Render and save the diagram\n",
    "    graph.render('contrastive_dataset', view=True)\n",
    "\n",
    "# Call the functions to generate the diagrams\n",
    "visualize_contrastive_model()\n",
    "visualize_contrastive_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = \"model/dataframe/train-aug.pkl\"\n",
    "test_data = \"model/dataframe/test.pkl\"\n",
    "val_data = \"model/dataframe/val.pkl\"\n",
    "train_df = pd.read_pickle(train_data)\n",
    "val_df = pd.read_pickle(test_data)\n",
    "test_df = pd.read_pickle(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Aspect Term</th>\n",
       "      <th>polarity_numeric</th>\n",
       "      <th>Aspect Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>though the service might be a little slow, the...</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>though the service might be a little slow, the...</td>\n",
       "      <td>service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>after reading other reviews i was expecting po...</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>after reading other reviews i was expecting po...</td>\n",
       "      <td>service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>i found that the food variety was great, and t...</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           Sentence Aspect Term  \\\n",
       "1   4  though the service might be a little slow, the...       staff   \n",
       "0   4  though the service might be a little slow, the...     service   \n",
       "3  14  after reading other reviews i was expecting po...       staff   \n",
       "2  14  after reading other reviews i was expecting po...     service   \n",
       "5  20  i found that the food variety was great, and t...       staff   \n",
       "\n",
       "   polarity_numeric  Aspect Number  \n",
       "1                 2              1  \n",
       "0                 0              0  \n",
       "3                 2              1  \n",
       "2                 0              0  \n",
       "5                 2              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = train_df['Aspect Term'].unique()\n",
    "\n",
    "print(len(counts))\n",
    "\n",
    "train_df=train_df.sort_values('id')\n",
    "display(train_df.head(5))\n",
    "# filtered_df = train_df[train_df['id'] == 2355]\n",
    "# (list(filtered_df['Sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHe works at Google.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m spacy\u001b[38;5;241m.\u001b[39mdisplacy\u001b[38;5;241m.\u001b[39mserve(doc, style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def visualize_hyperparameter_tuning():\n",
    "    # Create a new directed graph\n",
    "    graph = graphviz.Digraph(comment='Hyperparameter Tuning', graph_attr={'rankdir': 'TB', 'size': '12,12'})\n",
    "\n",
    "    # Define nodes\n",
    "    graph.node('start', 'Start', shape='ellipse', style='filled', fillcolor='lightblue')\n",
    "    graph.node('param_grid', 'Define Parameter Grid', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('subset_loop', 'Subset Loop', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.node('train_loop', 'Training Loop', shape='box', style='filled', fillcolor='lightyellow')\n",
    "    graph.node('train_model', 'Train Model', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('validation', 'Validation', shape='box', style='filled', fillcolor='lightpink')\n",
    "    graph.node('log_metrics', 'Log Metrics', shape='box', style='filled', fillcolor='lightgreen')\n",
    "    graph.node('select_best', 'Select Best Model', shape='box', style='filled', fillcolor='lightblue')\n",
    "    graph.node('end', 'End', shape='ellipse', style='filled', fillcolor='lightblue')\n",
    "\n",
    "    # Define edges\n",
    "    graph.edge('start', 'param_grid')\n",
    "    graph.edge('param_grid', 'subset_loop', label='For each parameter combination')\n",
    "    graph.edge('subset_loop', 'train_loop', label='For each subset')\n",
    "    graph.edge('train_loop', 'train_model', label='For each epoch')\n",
    "    graph.edge('train_model', 'validation', label='Evaluate on validation set')\n",
    "    graph.edge('validation', 'log_metrics', label='Log validation metrics')\n",
    "    graph.edge('log_metrics', 'train_loop', label='Continue training')\n",
    "    graph.edge('train_loop', 'subset_loop', label='Next subset')\n",
    "    graph.edge('subset_loop', 'select_best', label='All subsets completed')\n",
    "    graph.edge('select_best', 'end')\n",
    "\n",
    "    # Add loop annotations\n",
    "    graph.edge('train_loop', 'train_loop', label='Repeat for each epoch', dir='back', style='dashed')\n",
    "    graph.edge('subset_loop', 'subset_loop', label='Repeat for each subset', dir='back', style='dashed')\n",
    "\n",
    "    # Render and save the diagram\n",
    "    graph.render('hyperparameter_tuning', view=True)\n",
    "\n",
    "# Call the function to generate the diagram\n",
    "visualize_hyperparameter_tuning()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
